{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "LEARNING_RATE = 5e-4\n",
    "BATCH_SIZE = 256\n",
    "CLEAN_NUM = 16000\n",
    "ANOMALY_NUM = 1600\n",
    "DIRTYTYPE = \"plastic\"\n",
    "\n",
    "# 定义lambda值列表\n",
    "LAMBDA_LIST = [0] #[0.01]# [0.01, 0.02, 0.05]\n",
    "\n",
    "num_epochs = 100\n",
    "record_epochs = list(range(5, num_epochs + 1, 5))  # 每5个epoch记录一次\n",
    "\n",
    "# 加载数据\n",
    "data_path = '16000clean7dirty.pkl'\n",
    "\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "normal_images = data['clean'][:CLEAN_NUM] \n",
    "anomaly_images = data[DIRTYTYPE][:ANOMALY_NUM]#异常图片\n",
    "\n",
    "# 归一化\n",
    "def normalize_image(img):\n",
    "    x_min = img.min()\n",
    "    x_max = img.max()\n",
    "    img_norm = (img - x_min) / (x_max - x_min + 1e-8) \n",
    "    return img_norm.astype(np.float32)\n",
    "\n",
    "normal_images_norm = np.array([normalize_image(img) for img in normal_images])\n",
    "anomaly_images_norm = np.array([normalize_image(img) for img in anomaly_images])\n",
    "\n",
    "# 合并数据\n",
    "images = np.concatenate((normal_images_norm, anomaly_images_norm), axis=0)\n",
    "labels = np.array([0]*CLEAN_NUM + [1]*ANOMALY_NUM)\n",
    "\n",
    "# 调整维度顺序，从(H, W, C)变为(C, H, W)\n",
    "images = images.transpose((0, 3, 1, 2))\n",
    "print('数据形状：', images.shape)\n",
    "\n",
    "images_tensor = torch.from_numpy(images)\n",
    "labels_tensor = torch.from_numpy(labels)\n",
    "\n",
    "# 创建训练和评估的数据集和数据加载器\n",
    "train_dataset = TensorDataset(images_tensor, labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 评估数据集和数据加载器（不打乱顺序，并返回索引）\n",
    "class IndexedTensorDataset(Dataset):\n",
    "    def __init__(self, images_tensor, labels_tensor):\n",
    "        self.images_tensor = images_tensor\n",
    "        self.labels_tensor = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images_tensor[idx]\n",
    "        label = self.labels_tensor[idx]\n",
    "        return image, label, idx  \n",
    "\n",
    "eval_dataset = IndexedTensorDataset(images_tensor, labels_tensor)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# CAE模型\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.encoder_fc1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 4096),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder_fc2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.decoder_fc1 = nn.Sequential(\n",
    "            nn.Linear(256, 4096),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder_fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 64 * 28 * 28),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        batch_size = x.size(0)\n",
    "        x_flat = x_enc.contiguous().view(batch_size, -1)\n",
    "        latent1 = self.encoder_fc1(x_flat)  \n",
    "        latent2 = self.encoder_fc2(latent1)  \n",
    "\n",
    "        x_dec_fc1 = self.decoder_fc1(latent2)  \n",
    "        x_dec_fc2 = self.decoder_fc2(x_dec_fc1)\n",
    "        x_dec = x_dec_fc2.view(batch_size, 64, 28, 28)\n",
    "        x_recon = self.decoder(x_dec)\n",
    "        return x_recon, latent2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 遍历不同的lambda值\n",
    "for LAMBDA in LAMBDA_LIST:\n",
    "    print(f\"\\n***** 开始训练，lambda = {LAMBDA} *****\")\n",
    "    # 创建结果目录\n",
    "    results_dir = f\"results_mse16000_{DIRTYTYPE}/{LAMBDA}_{BATCH_SIZE}_0.0005\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    model = CAE().to(device)\n",
    "    criterion = nn.MSELoss(reduction='none')  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # 记录指标的字典\n",
    "    loss_records = []    \n",
    "    mse_loss_records = {}     \n",
    "    rc_records = {}      \n",
    "    smoothed_rc_records = {}  \n",
    "    auc_records = {}  \n",
    "\n",
    "    all_indices = np.arange(len(images_tensor))\n",
    "    reference_indices = np.random.choice(all_indices, size=800, replace=False)\n",
    "    reference_images = images_tensor[reference_indices].to(device)\n",
    "    '''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, reference_latent = model(reference_images)\n",
    "    reference_latent = reference_latent.detach()  # shape: (500, 256)\n",
    "    '''\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            img, labels = data\n",
    "            img = img.to(device)\n",
    "            \n",
    "            output, latent = model(img)  \n",
    "            loss_recon = criterion(output, img)  \n",
    "\n",
    "            mse_loss = loss_recon.mean(dim=[1,2,3])  \n",
    "\n",
    "            _, reference_latent = model(reference_images)\n",
    "            distances = torch.cdist(latent, reference_latent)  \n",
    "\n",
    "            min_indices = torch.argmin(distances, dim=1)  \n",
    "            nearest_latent = reference_latent[min_indices]  \n",
    "\n",
    "            l2_loss = (latent - nearest_latent).pow(2).mean(dim=1)  \n",
    "\n",
    "            total_loss_batch = mse_loss + LAMBDA * l2_loss\n",
    "\n",
    "            loss_mean = total_loss_batch.mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_mean.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss_mean.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        loss_records.append(avg_loss)\n",
    "        print(f\"Lambda {LAMBDA}, Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        # 记录MSE、RC、平滑RC和AUC\n",
    "        if epoch in record_epochs:\n",
    "            model.eval()\n",
    "            mse_loss_values = []\n",
    "            rc_values = []\n",
    "            indices_list = []  \n",
    "            labels_list = []  \n",
    "            latent_values = []\n",
    "            anomaly_indices = []\n",
    "            with torch.no_grad():\n",
    "                for data in eval_loader:\n",
    "                    img, labels, indices = data\n",
    "                    img = img.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    indices = indices.to(device)\n",
    "                    \n",
    "                    # 前向传播\n",
    "                    output, latent = model(img)\n",
    "                    latent_values.append(latent.cpu().numpy())\n",
    "                    anomaly_indices.extend(indices[labels == 1].cpu().numpy())\n",
    "                    loss = criterion(output, img)  \n",
    "                    \n",
    "                    # 计算MSE\n",
    "                    mse_loss  = loss.mean(dim=[1,2,3]) \n",
    "                    mse_loss_values.extend(mse_loss.cpu().numpy())\n",
    "                    \n",
    "                    # 计算RC\n",
    "                    # 展平\n",
    "                    img_flat = img.view(img.size(0), -1) \n",
    "                    output_flat = output.view(output.size(0), -1)\n",
    "                    \n",
    "                    img_mean = img_flat.mean(dim=1, keepdim=True)\n",
    "                    output_mean = output_flat.mean(dim=1, keepdim=True)\n",
    "                    \n",
    "                    img_centered = img_flat - img_mean \n",
    "                    output_centered = output_flat - output_mean\n",
    "                    \n",
    "                    numerator = torch.sum(img_centered * output_centered, dim=1) \n",
    "                    \n",
    "                    img_norm = torch.norm(img_centered, p=2, dim=1) \n",
    "                    output_norm = torch.norm(output_centered, p=2, dim=1)\n",
    "                    \n",
    "                    denominator = img_norm * output_norm + 1e-8\n",
    "                    rc = numerator / denominator \n",
    "                    \n",
    "                    rc_values.extend(rc.cpu().numpy())\n",
    "                    indices_list.extend(indices.cpu().numpy())\n",
    "                    labels_list.extend(labels.cpu().numpy())\n",
    "            \n",
    "            latent_values = np.concatenate(latent_values, axis=0)\n",
    "            anomaly_indices = np.array(anomaly_indices)\n",
    "            \n",
    "            # np.save(f\"{epoch}.npy\", latent_values)\n",
    "            # np.save(f\"index{epoch}.npy\", anomaly_indices)\n",
    "            \n",
    "            # 对RC值进行平滑处理\n",
    "            rc_values_array = np.array(rc_values)\n",
    "            smoothed_rc_values = median_filter(rc_values_array, size=1001, mode='reflect')\n",
    "            \n",
    "            # 计算AUC值\n",
    "            auc_value = roc_auc_score(labels_list, smoothed_rc_values)\n",
    "            print(f\"Lambda {LAMBDA}, Epoch [{epoch}] AUC: {auc_value:.6f}\")\n",
    "            \n",
    "            # 保存记录\n",
    "            mse_loss_records[epoch] = (mse_loss_values, indices_list)\n",
    "            rc_records[epoch] = (rc_values, indices_list)\n",
    "            smoothed_rc_records[epoch] = (smoothed_rc_values, indices_list)\n",
    "            auc_records[epoch] = auc_value\n",
    "    \n",
    "    # 保存所有记录到文件\n",
    "    np.save(os.path.join(results_dir, 'loss_records.npy'), np.array(loss_records))\n",
    "    np.save(os.path.join(results_dir, 'mse_loss_records.npy'), mse_loss_records)\n",
    "    np.save(os.path.join(results_dir, 'rc_records.npy'), rc_records)\n",
    "    np.save(os.path.join(results_dir, 'smoothed_rc_records.npy'), smoothed_rc_records)\n",
    "    np.save(os.path.join(results_dir, 'auc_records.npy'), auc_records)\n",
    "    print(f\"Lambda {LAMBDA} 的所有结果已保存到 {results_dir}\")\n",
    "\n",
    "    # 保存AUC值到文件\n",
    "    auc_file_path = os.path.join(results_dir, 'auc_values.txt')\n",
    "    with open(auc_file_path, 'w') as f:\n",
    "        for epoch in sorted(auc_records.keys()):\n",
    "            f.write(f\"Epoch {epoch}: AUC = {auc_records[epoch]:.6f}\\n\")\n",
    "    print(f\"Lambda {LAMBDA} 的AUC值已保存到 {auc_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
